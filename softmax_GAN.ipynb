{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'bsize' : 128,# Batch size during training.\n",
    "    'b_output':128, # output from first Dense layer\n",
    "    'imsize' : 64,# Spatial size of training images. All images will be resized to this size during preprocessing.\n",
    "    'nc' : 3,# Number of channles in the training images. For coloured images this is 3.\n",
    "    'nz' : 100,# Size of the Z latent vector (the input to the generator).\n",
    "    'nepochs' : 100,# Number of training epochs.\n",
    "    'lr' : 0.0002,# Learning rate for optimizers\n",
    "    'beta1' : 0.5,# Beta1 hyperparam for Adam optimizer\n",
    "    'beta2': 0.999, # Beta2 hyperparam for Adam optimizer\n",
    "    'save_epoch' : 2 # Save step.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing and Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset link\n",
    "# https://drive.google.com/drive/folders/0B7EVK8r0v71pTUZsaXdaSnZBZzg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = \"data/\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(params['imsize']),\n",
    "    transforms.CenterCrop(params['imsize']),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "device = torch.device(\"cudo:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "dataset = dset.ImageFolder(root=dataset_root, transform=transform)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=params['bsize'], shuffle=True)\n",
    "\n",
    "sample_batch = next(iter(dataloader))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis('off')\n",
    "plt.title('Training Images')\n",
    "plt.imshow(np.transpose(vutils.make_grid(sample_batch[0].to(device)[:64], padding=2, normalize=True).cpu(), (1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Input is the latent vector Z.\n",
    "        self.linear1 = nn.Linear(params['nz'], params['b_output'])\n",
    "        self.bn1 = nn.BatchNorm1d(params['b_output'], 0.8)\n",
    "        \n",
    "        # Input is b_output\n",
    "        self.linear2 = nn.Linear(params['b_output'], params['b_output']*2)\n",
    "        self.bn2 = nn.BatchNorm1d(params['b_output']*2, 0.8)\n",
    "        \n",
    "        # Input is b_output*2\n",
    "        self.linear3 = nn.Linear(params['b_output']*2, params['b_output']*4)\n",
    "        self.bn3 = nn.BatchNorm1d(params['b_output']*4, 0.8)\n",
    "        \n",
    "        # Input is b_output*3\n",
    "        self.linear4 = nn.Linear(params['b_output']*4, params['b_output']*8)\n",
    "        self.bn4 = nn.BatchNorm1d(params['b_output']*8, 0.8)\n",
    "        \n",
    "        # Input is b_output*4\n",
    "        self.linear5 = nn.Linear(params['b_output']*8, params['imsize']*params['imsize']*params['nc'])\n",
    "\n",
    "        \n",
    "    def forward(self, img):\n",
    "        img = F.leaky_relu(self.bn1(self.linear1(img)), 0.2, False)\n",
    "        img = F.leaky_relu(self.bn2(self.linear2(img)), 0.2, False)\n",
    "        img = F.leaky_relu(self.bn3(self.linear3(img)), 0.2, False)\n",
    "        img = F.leaky_relu(self.bn4(self.linear4(img)), 0.2, False)\n",
    "        img = torch.tanh(self.linear5(img))\n",
    "        \n",
    "        img = img.view(params['bsize'],  params['nc'], params['imsize'], params['imsize'])\n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.linear1 = nn.Linear(params['imsize']**2*params['nc'], params['b_output']*8)\n",
    "        self.linear2 = nn.Linear(params['b_output']*8, params['b_output']*4)\n",
    "        self.linear3 = nn.Linear(params['b_output']*4, params['b_output']*2)\n",
    "        self.linear4 = nn.Linear(params['b_output']*2, 1)\n",
    "        \n",
    "    def forward(self, img):\n",
    "        img = img.view(img.shape[0], -1)\n",
    "        img = F.leaky_relu(self.linear1(img), 0.2, False)\n",
    "        img = F.leaky_relu(self.linear2(img), 0.2, False)\n",
    "        img = F.leaky_relu(self.linear3(img), 0.2, False)\n",
    "        img = self.linear4(img)\n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator(params)\n",
    "netD = Discriminator(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "if cuda:\n",
    "    netG.cuda()\n",
    "    netD.cuda()\n",
    "    adversarial_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generator Network: \", netG)\n",
    "print(\"Discriminator Network: \", netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(netG.parameters(), lr=params['lr'], betas=(params['beta1'], params['beta2']))\n",
    "optimizer_D = torch.optim.Adam(netD.parameters(), lr=params['lr'], betas=(params['beta1'], params['beta2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_loss = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(x):\n",
    "    return torch.log(x + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(params['nepochs']):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "\n",
    "        batch_size = imgs.shape[0]\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        g_target = 1 / (batch_size * 2)\n",
    "        d_target = 1 / batch_size\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = imgs\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        #z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], params['nz']))))\n",
    "        z = torch.normal(0, 1, (imgs.shape[0], params['nz']))\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = netG(z)\n",
    "\n",
    "        d_real = netD(real_imgs)\n",
    "        d_fake = netD(gen_imgs.detach())\n",
    "        \n",
    "        # Partition function\n",
    "        Z = torch.sum(torch.exp(-d_real)) + torch.sum(torch.exp(-d_fake))\n",
    "        # Calculate loss of discriminator and update\n",
    "        d_loss = d_target * torch.sum(d_real) + log(Z)\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        d_loss.backward(retain_graph=True)        \n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        #Calculate loss of generator and update\n",
    "        g_loss = g_target * (torch.sum(d_real) + torch.sum(d_fake)) + log(Z)\n",
    "        optimizer_D.step()\n",
    "        g_loss.backward()\n",
    "\n",
    "        optimizer_G.step()\n",
    "\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "            % (epoch, params['nepochs'], i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
